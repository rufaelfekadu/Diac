# transformer.tashkeela.yml

DATA:
  TRAIN_PATH: data/tashkeela/train.txt
  VAL_PATH: data/tashkeela/val.txt
  TEST_PATH: data/tashkeela/test.txt
  MAX_LENGTH: 100

MODEL:
  TYPE: LSTM
  MAXLEN: 102
  VOCAB_SIZE: 77
  ASR_VOCAB_SIZE: 91
  D_MODEL: 128
  NUM_HEADS: 4
  DFF: 128
  NUM_BLOCKS: 2
  DROPOUT_RATE: 0.5
  OUTPUT_SIZE: 19
  USE_ASR: False
  WITH_CONN: False # use concatenation to combine
  PRETRAINED_PATH: null
  LOAD_TEXT_BRANCH_ONLY: True

TRAIN:
  DEVICE: cuda
  BATCH_SIZE: 128
  NUM_EPOCHS: 10
  LEARNING_RATE: 0.001
  SAVE_DIR: checkpoints/lstm-tashkeela
  SAVE_FREQ: 40
  EVAL_FREQ: 1
  
INFERENCE:
  MAX_LENGTH: 100
  USE_ASR: False
  DEVICE: cuda
  BATCH_SIZE: 16
  MODEL_PATH: checkpoints/lstm-tashkeela/best_model.pth
  ASR_MODEL_NAME: "sashat/whisper-medium-ClassicalAr"
  OUTPUT_PATH: checkpoints/lstm-tashkeela/results/predictions.txt